{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image, ImageStat\n",
    "import sys\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(dir):\n",
    "    file_list=listdir(dir)\n",
    "    for filename in file_list:\n",
    "        print (filename)\n",
    "        if \"panorama\" in filename and \"cropped\" not in filename:\n",
    "            path=\"\"\n",
    "            path=dir+filename\n",
    "            im=Image.open(path)\n",
    "            out=im.resize((416,208),Image.ANTIALIAS)\n",
    "            print (\"%s has been resized\"%filename)\n",
    "            out.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path):\n",
    "    \"\"\"\n",
    "    Get a numpy 2D array of an image so that one can access RGBA[x][y] or RGBA[x,y].\n",
    "    \n",
    "    Also get a cropped image for further use for hsv and k-means clustering\n",
    "    \n",
    "    \"\"\"\n",
    "    origin = Image.open(image_path, 'r')\n",
    "    width, height = origin.size\n",
    "    area = (0, 0, width, 0.5*height)\n",
    "    image = origin.crop(area) # crop top half of the image\n",
    "#     result = Image.fromarray(image.astype(np.uint8))\n",
    "    image.save(file+\"_cropped.png\")\n",
    "    width, height = image.size\n",
    "#     print (image.size)\n",
    "    pixel_values = list(image.getdata())\n",
    "    if image.mode == 'RGBA':\n",
    "        channels = 4\n",
    "    elif image.mode == 'L':\n",
    "        channels = 1\n",
    "    else:\n",
    "        print(\"Unknown mode: %s\" % image.mode)\n",
    "        return None\n",
    "#     pixel_values = np.array(pixel_values).reshape((width, height, channels))\n",
    "    pixel_values = np.array(pixel_values).reshape((height, width, channels))\n",
    "#     print (np.shape(pixel_values))\n",
    "\n",
    "    return pixel_values,image,origin #return pixels matrix with RGBA value, and cropped half image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bri(pixels):\n",
    "    \"\"\"\n",
    "    Get a numpy 2D array of an image so that one can access brightness[x][y]\n",
    "       \n",
    "    \"\"\"\n",
    "    brightness=[[0 for x in range(len(pixels[0]))] for y in range(len(pixels))]\n",
    "    # Matrix = [[0 for x in range(w)] for y in range(h)]\n",
    "    for i in range(len(pixels)):\n",
    "        for j in range(len(pixels[0])):\n",
    "            R,G,B,A=pixels[i,j]\n",
    "            brightness[i][j]=(0.2126*R + 0.7152*G + 0.0722*B)/255\n",
    "    return brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blackC-1010_-37.808706898558945_144.98444713162672_panorama.png_cropped.png\n",
      "bigS-1060_-37.80868577546702_144.9850156495497_panorama.png\n",
      "bigS-1060_-37.80868577546702_144.9850156495497_panorama.png has been resized\n",
      "blackC-1010_-37.808706898558945_144.98444713162672_panorama.png\n",
      "blackC-1010_-37.808706898558945_144.98444713162672_panorama.png has been resized\n",
      "whiteB-0100_-37.80909086146474_144.9741000486449_panorama.png\n",
      "whiteB-0100_-37.80909086146474_144.9741000486449_panorama.png has been resized\n",
      "sky-1270_-37.80859702864577_144.98740342127365_panorama.png_cropped.png\n",
      "sky-1810_-37.80836860123093_144.99354337933758_panorama.png\n",
      "sky-1810_-37.80836860123093_144.99354337933758_panorama.png has been resized\n",
      "bigS-2290_-37.80816528711204_144.99900108792806_panorama.png\n",
      "bigS-2290_-37.80816528711204_144.99900108792806_panorama.png has been resized\n",
      "tree-0110_-37.809086647010126_144.97421375343805_panorama.png_cropped.png\n",
      "MNIST_data\n",
      "buliding-0140_-37.80907400299053_144.9745548677395_panorama.png_cropped.png\n",
      "bigS-0790_-37.80879980770527_144.98194564890238_panorama.png\n",
      "bigS-0790_-37.80879980770527_144.98194564890238_panorama.png has been resized\n",
      "sky-1810_-37.80836860123093_144.99354337933758_panorama.png_cropped.png\n",
      ".DS_Store\n",
      "whiteB-0670_-37.80885046312688_144.98058120112736_panorama.png_cropped.png\n",
      "whiteB-0300_-37.80900655160748_144.9763741420407_panorama.png_cropped.png\n",
      "tree-0110_-37.809086647010126_144.97421375343805_panorama.png\n",
      "tree-0110_-37.809086647010126_144.97421375343805_panorama.png has been resized\n",
      "blackC-0970_-37.80872379506533_144.98399231705417_panorama.png_cropped.png\n",
      "buliding-1760_-37.808389765304874_144.99297486629814_panorama.png_cropped.png\n",
      "tree-2310_-37.808156810226265_144.99922849180032_panorama.png\n",
      "tree-2310_-37.808156810226265_144.99922849180032_panorama.png has been resized\n",
      "sky-2420_-37.80811017954074_145.00047921216438_panorama.png\n",
      "sky-2420_-37.80811017954074_145.00047921216438_panorama.png has been resized\n",
      "sky-1360_-37.808558979540216_144.98842675025523_panorama.png\n",
      "sky-1360_-37.808558979540216_144.98842675025523_panorama.png has been resized\n",
      "bigS-0790_-37.80879980770527_144.98194564890238_panorama.png_cropped.png\n",
      "buliding-0380_-37.80897281542424_144.97728377794476_panorama.png_cropped.png\n",
      "tree-2310_-37.808156810226265_144.99922849180032_panorama.png_cropped.png\n",
      "blackC-2520_-37.8080677765338_145.00161622930622_panorama.png_cropped.png\n",
      "blackC-0970_-37.80872379506533_144.98399231705417_panorama.png\n",
      "blackC-0970_-37.80872379506533_144.98399231705417_panorama.png has been resized\n",
      "tree-0040_-37.80911614589736_144.9734178196137_panorama.png\n",
      "tree-0040_-37.80911614589736_144.9734178196137_panorama.png has been resized\n",
      "whiteB-1140_-37.80865197283703_144.98592527754985_panorama.png_cropped.png\n",
      "buliding-1760_-37.808389765304874_144.99297486629814_panorama.png\n",
      "buliding-1760_-37.808389765304874_144.99297486629814_panorama.png has been resized\n",
      "buliding-0140_-37.80907400299053_144.9745548677395_panorama.png\n",
      "buliding-0140_-37.80907400299053_144.9745548677395_panorama.png has been resized\n",
      "whiteB-0300_-37.80900655160748_144.9763741420407_panorama.png\n",
      "whiteB-0300_-37.80900655160748_144.9763741420407_panorama.png has been resized\n",
      "tree-0900_-37.80875335974397_144.9831963910514_panorama.png\n",
      "tree-0900_-37.80875335974397_144.9831963910514_panorama.png has been resized\n",
      "tree-0920_-37.80874491323935_144.9834237985458_panorama.png_cropped.png\n",
      "blackC-1630_-37.80844477911086_144.99149673087072_panorama.png\n",
      "blackC-1630_-37.80844477911086_144.99149673087072_panorama.png has been resized\n",
      "bigS-2290_-37.80816528711204_144.99900108792806_panorama.png_cropped.png\n",
      "bigS-0860_-37.80877025144173_144.98274157590654_panorama.png_cropped.png\n",
      "blackC-2520_-37.8080677765338_145.00161622930622_panorama.png\n",
      "blackC-2520_-37.8080677765338_145.00161622930622_panorama.png has been resized\n",
      "bigS-0820_-37.80878714139091_144.98228676055362_panorama.png_cropped.png\n",
      "tree-0920_-37.80874491323935_144.9834237985458_panorama.png\n",
      "tree-0920_-37.80874491323935_144.9834237985458_panorama.png has been resized\n",
      "tree-0040_-37.80911614589736_144.9734178196137_panorama.png_cropped.png\n",
      "sky-1100_-37.80866887502632_144.98547046365388_panorama.png\n",
      "sky-1100_-37.80866887502632_144.98547046365388_panorama.png has been resized\n",
      "sky-1270_-37.80859702864577_144.98740342127365_panorama.png\n",
      "sky-1270_-37.80859702864577_144.98740342127365_panorama.png has been resized\n",
      "classification.ipynb\n",
      "sky-2420_-37.80811017954074_145.00047921216438_panorama.png_cropped.png\n",
      "whiteB-0030_-37.80912035958696_144.97330411472973_panorama.png_cropped.png\n",
      "bigS-0820_-37.80878714139091_144.98228676055362_panorama.png\n",
      "bigS-0820_-37.80878714139091_144.98228676055362_panorama.png has been resized\n",
      "sky-1100_-37.80866887502632_144.98547046365388_panorama.png_cropped.png\n",
      "sky-1360_-37.808558979540216_144.98842675025523_panorama.png_cropped.png\n",
      "blackC-0850_-37.808774474092964_144.98262787208782_panorama.png\n",
      "blackC-0850_-37.808774474092964_144.98262787208782_panorama.png has been resized\n",
      ".ipynb_checkpoints\n",
      "tree-0900_-37.80875335974397_144.9831963910514_panorama.png_cropped.png\n",
      "bigS-1060_-37.80868577546702_144.9850156495497_panorama.png_cropped.png\n",
      "buliding-0380_-37.80897281542424_144.97728377794476_panorama.png\n",
      "buliding-0380_-37.80897281542424_144.97728377794476_panorama.png has been resized\n",
      "whiteB-0030_-37.80912035958696_144.97330411472973_panorama.png\n",
      "whiteB-0030_-37.80912035958696_144.97330411472973_panorama.png has been resized\n",
      "blackC-0850_-37.808774474092964_144.98262787208782_panorama.png_cropped.png\n",
      "bigS-0860_-37.80877025144173_144.98274157590654_panorama.png\n",
      "bigS-0860_-37.80877025144173_144.98274157590654_panorama.png has been resized\n",
      "whiteB-1140_-37.80865197283703_144.98592527754985_panorama.png\n",
      "whiteB-1140_-37.80865197283703_144.98592527754985_panorama.png has been resized\n",
      "whiteB-0670_-37.80885046312688_144.98058120112736_panorama.png\n",
      "whiteB-0670_-37.80885046312688_144.98058120112736_panorama.png has been resized\n",
      "blackC-1630_-37.80844477911086_144.99149673087072_panorama.png_cropped.png\n",
      "whiteB-0100_-37.80909086146474_144.9741000486449_panorama.png_cropped.png\n"
     ]
    }
   ],
   "source": [
    "path1 = \"/Users/yimingqiu/Desktop/class/\"\n",
    "files= listdir(path1)\n",
    "\n",
    "convert(path1)\n",
    "# Sgray=0.0\n",
    "# for K in range(4, 16):\n",
    "# while Sgray<=1:\n",
    "#     true_po_list=[]\n",
    "#     precision_list=[]\n",
    "#     edge_list=[]\n",
    "    # print (files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigS-0790_-37.80879980770527_144.98194564890238_panorama.png (1, 43264)\n",
      "bigS-0820_-37.80878714139091_144.98228676055362_panorama.png (2, 43264)\n",
      "bigS-0860_-37.80877025144173_144.98274157590654_panorama.png (3, 43264)\n",
      "bigS-1060_-37.80868577546702_144.9850156495497_panorama.png (4, 43264)\n",
      "bigS-2290_-37.80816528711204_144.99900108792806_panorama.png (5, 43264)\n",
      "blackC-0850_-37.808774474092964_144.98262787208782_panorama.png (6, 43264)\n",
      "blackC-0970_-37.80872379506533_144.98399231705417_panorama.png (7, 43264)\n",
      "blackC-1010_-37.808706898558945_144.98444713162672_panorama.png (8, 43264)\n",
      "blackC-1630_-37.80844477911086_144.99149673087072_panorama.png (9, 43264)\n",
      "blackC-2520_-37.8080677765338_145.00161622930622_panorama.png (10, 43264)\n",
      "buliding-0140_-37.80907400299053_144.9745548677395_panorama.png (11, 43264)\n",
      "buliding-0380_-37.80897281542424_144.97728377794476_panorama.png (12, 43264)\n",
      "buliding-1760_-37.808389765304874_144.99297486629814_panorama.png (13, 43264)\n",
      "sky-1100_-37.80866887502632_144.98547046365388_panorama.png (14, 43264)\n",
      "sky-1270_-37.80859702864577_144.98740342127365_panorama.png (15, 43264)\n",
      "sky-1360_-37.808558979540216_144.98842675025523_panorama.png (16, 43264)\n",
      "sky-1810_-37.80836860123093_144.99354337933758_panorama.png (17, 43264)\n",
      "sky-2420_-37.80811017954074_145.00047921216438_panorama.png (18, 43264)\n",
      "tree-0040_-37.80911614589736_144.9734178196137_panorama.png (19, 43264)\n",
      "tree-0110_-37.809086647010126_144.97421375343805_panorama.png (20, 43264)\n",
      "tree-0900_-37.80875335974397_144.9831963910514_panorama.png (21, 43264)\n",
      "tree-0920_-37.80874491323935_144.9834237985458_panorama.png (22, 43264)\n",
      "tree-2310_-37.808156810226265_144.99922849180032_panorama.png (23, 43264)\n",
      "whiteB-0030_-37.80912035958696_144.97330411472973_panorama.png (24, 43264)\n",
      "whiteB-0100_-37.80909086146474_144.9741000486449_panorama.png (25, 43264)\n",
      "whiteB-0300_-37.80900655160748_144.9763741420407_panorama.png (26, 43264)\n",
      "whiteB-0670_-37.80885046312688_144.98058120112736_panorama.png (27, 43264)\n",
      "whiteB-1140_-37.80865197283703_144.98592527754985_panorama.png (28, 43264)\n",
      "[0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6062588235294116, 0.6062588235294116, 0.6152392156862745, 0.6144054901960785, 0.6113176470588235, 0.6113176470588235, 0.6113176470588235, 0.6113176470588235, 0.6113176470588235, 0.6113176470588235, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6121309803921569, 0.6121309803921569, 0.6121309803921569, 0.6121309803921569, 0.6115647058823529, 0.6118478431372548, 0.6118478431372548, 0.6146525490196079, 0.6079262745098039, 0.6107309803921568, 0.6079262745098039, 0.6098972549019607, 0.6098972549019607, 0.6098972549019607, 0.6098972549019607, 0.6098972549019607, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6082094117647059, 0.6042878431372549, 0.6042878431372549, 0.6082094117647059, 0.6073756862745098, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6107309803921568, 0.6068094117647059, 0.6068094117647059, 0.6070925490196077, 0.6107309803921568, 0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6101803921568626, 0.6121309803921569, 0.6121309803921569, 0.6121309803921569, 0.6121309803921569, 0.612964705882353, 0.612964705882353, 0.612964705882353, 0.612964705882353, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077, 0.6160525490196077]\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "train_x = []\n",
    "for file in sorted(files):\n",
    "    if \"panorama\" in file and \"cropped\" not in file:\n",
    "#         file=path1+file\n",
    "        pixels,image,origin=get_image(file)\n",
    "#         print (np.shape(pixels))\n",
    "            # print (pixel1)\n",
    "        brightness=get_bri(pixels)\n",
    "        \n",
    "#             edge_cal(file)\n",
    "        brightness[i]=np.asarray(brightness)\n",
    "        brightness[i]=brightness[i].reshape(-1)\n",
    "        train_x.append(brightness[i])\n",
    "        print(file,np.shape(train_x))\n",
    "        i+=1\n",
    "#         mark_sky(pixels,label2,origin,file,Sgray)\n",
    "print(brightness[0][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 6)\n"
     ]
    }
   ],
   "source": [
    "train_y = []\n",
    "for i in range(5):\n",
    "    train_y.append([1,0,0,0,0,0])\n",
    "for i in range(5):\n",
    "    train_y.append([0,1,0,0,0,0])\n",
    "for i in range(3):\n",
    "    train_y.append([0,0,1,0,0,0])\n",
    "for i in range(5):\n",
    "    train_y.append([0,0,0,1,0,0])\n",
    "for i in range(5):\n",
    "    train_y.append([0,0,0,0,1,0])\n",
    "for i in range(5):\n",
    "    train_y.append([0,0,0,0,0,1])\n",
    "\n",
    "print(np.shape(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 43264) (27, 6)\n"
     ]
    }
   ],
   "source": [
    "test_x = train_x[0]\n",
    "test_y = train_y[0]\n",
    "train_x=np.delete(train_x,1,0)\n",
    "train_y=np.delete(train_y,1,0)\n",
    "print(np.shape(train_x),np.shape(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 43264)\n"
     ]
    }
   ],
   "source": [
    "test_x=test_x.reshape((1,-1))\n",
    "print(np.shape(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "test_y= np.array(test_y)\n",
    "test_y=test_y.reshape((1,-1))\n",
    "print(np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0,Testing Accuracy 0.0\n",
      "Iter 1,Testing Accuracy 0.0\n",
      "Iter 2,Testing Accuracy 0.0\n",
      "Iter 3,Testing Accuracy 0.0\n",
      "Iter 4,Testing Accuracy 0.0\n",
      "Iter 5,Testing Accuracy 0.0\n",
      "Iter 6,Testing Accuracy 0.0\n",
      "Iter 7,Testing Accuracy 0.0\n",
      "Iter 8,Testing Accuracy 0.0\n",
      "Iter 9,Testing Accuracy 0.0\n",
      "Iter 10,Testing Accuracy 0.0\n",
      "Iter 11,Testing Accuracy 0.0\n",
      "Iter 12,Testing Accuracy 0.0\n",
      "Iter 13,Testing Accuracy 0.0\n",
      "Iter 14,Testing Accuracy 0.0\n",
      "Iter 15,Testing Accuracy 0.0\n",
      "Iter 16,Testing Accuracy 0.0\n",
      "Iter 17,Testing Accuracy 0.0\n",
      "Iter 18,Testing Accuracy 0.0\n",
      "Iter 19,Testing Accuracy 0.0\n",
      "Iter 20,Testing Accuracy 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# batch_size = 100\n",
    "\n",
    "# n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "batch_size=1\n",
    "\n",
    "#placeholder\n",
    "x = tf.placeholder(tf.float32,[None,43264])\n",
    "y = tf.placeholder(tf.float32,[None,6])\n",
    "\n",
    "#simple NN\n",
    "W = tf.Variable(tf.zeros([43264,6]))\n",
    "b = tf.Variable(tf.zeros([6]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W)+b)\n",
    "\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#gredient decent\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#save results\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))#argmax返回一维张量中最大的值所在的位置\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            batch_xs,batch_ys =  train_x,train_y\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:test_x,y:test_y})\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
