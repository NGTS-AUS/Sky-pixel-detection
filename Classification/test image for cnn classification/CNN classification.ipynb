{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image, ImageStat\n",
    "import sys\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(dir):\n",
    "    file_list=listdir(dir)\n",
    "    for filename in file_list:\n",
    "        if \"panorama\" in filename and \"cropped\" not in filename:\n",
    "            path=\"\"\n",
    "            path=dir+filename\n",
    "            im=Image.open(path)\n",
    "            out=im.resize((104,208),Image.ANTIALIAS)\n",
    "            print (\"%s has been resized\"%filename)\n",
    "            out.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0040_-37.80911614589736_144.9734178196137_panorama.png has been resized\n",
      "0110_-37.809086647010126_144.97421375343805_panorama.png has been resized\n",
      "0790_-37.80879980770527_144.98194564890238_panorama.png has been resized\n",
      "0820_-37.80878714139091_144.98228676055362_panorama.png has been resized\n",
      "0860_-37.80877025144173_144.98274157590654_panorama.png has been resized\n",
      "0900_-37.80875335974397_144.9831963910514_panorama.png has been resized\n",
      "0920_-37.80874491323935_144.9834237985458_panorama.png has been resized\n",
      "1060_-37.80868577546702_144.9850156495497_panorama.png has been resized\n",
      "2310_-37.808156810226265_144.99922849180032_panorama.png has been resized\n"
     ]
    }
   ],
   "source": [
    "path1 = r\"C:\\\\Users\\\\35252\\\\Desktop\\\\class\\\\\"\n",
    "files= listdir(path1)\n",
    "\n",
    "convert(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path):\n",
    "    \"\"\"\n",
    "    Get a numpy 2D array of an image so that one can access RGBA[x][y] or RGBA[x,y].\n",
    "    \n",
    "    Also get a cropped image for further use for hsv and k-means clustering\n",
    "    \n",
    "    \"\"\"\n",
    "    origin = Image.open(image_path, 'r')\n",
    "    width, height = origin.size\n",
    "    area = (0, 0, width, 0.5*height)\n",
    "    image = origin.crop(area) # crop top half of the image\n",
    "#     result = Image.fromarray(image.astype(np.uint8))\n",
    "    image.save(file+\"_cropped.png\")\n",
    "    width, height = image.size\n",
    "#     print (image.size)\n",
    "    pixel_values = list(image.getdata())\n",
    "    if image.mode == 'RGBA':\n",
    "        channels = 4\n",
    "    elif image.mode == 'L':\n",
    "        channels = 1\n",
    "    else:\n",
    "        print(\"Unknown mode: %s\" % image.mode)\n",
    "        return None\n",
    "    pixel_values = np.array(pixel_values).reshape((height, width, channels))\n",
    "\n",
    "    return pixel_values #return pixels matrix with RGBA value, and cropped half image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_array(pixels):\n",
    "    \"\"\"\n",
    "    Get a numpy 2D array of an image so that one can access brightness[x][y]\n",
    "       \n",
    "    \"\"\"\n",
    "    rgb=[[0 for x in range(len(pixels[0]))] for y in range(len(pixels))]\n",
    "    # Matrix = [[0 for x in range(w)] for y in range(h)]\n",
    "    for i in range(len(pixels)):\n",
    "        for j in range(len(pixels[0])):\n",
    "            R,G,B,A=pixels[i,j]\n",
    "            rgb[i][j]=[R,G,B]\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 104, 3)\n",
      "0040_-37.80911614589736_144.9734178196137_panorama.png (1, 10816, 3)\n",
      "(104, 104, 3)\n",
      "0110_-37.809086647010126_144.97421375343805_panorama.png (2, 10816, 3)\n",
      "(104, 104, 3)\n",
      "0790_-37.80879980770527_144.98194564890238_panorama.png (3, 10816, 3)\n",
      "(104, 104, 3)\n",
      "0820_-37.80878714139091_144.98228676055362_panorama.png (4, 10816, 3)\n",
      "(104, 104, 3)\n",
      "0860_-37.80877025144173_144.98274157590654_panorama.png (5, 10816, 3)\n",
      "(104, 104, 3)\n",
      "0900_-37.80875335974397_144.9831963910514_panorama.png (6, 10816, 3)\n",
      "(104, 104, 3)\n",
      "0920_-37.80874491323935_144.9834237985458_panorama.png (7, 10816, 3)\n",
      "(104, 104, 3)\n",
      "1060_-37.80868577546702_144.9850156495497_panorama.png (8, 10816, 3)\n",
      "(104, 104, 3)\n",
      "2310_-37.808156810226265_144.99922849180032_panorama.png (9, 10816, 3)\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "for file in sorted(files):\n",
    "    if \"panorama\" in file and \"cropped\" not in file:\n",
    "#         file=path1+file\n",
    "        pixels =get_image(file)\n",
    "#         print (np.shape(pixels))\n",
    "            # print (pixel1)\n",
    "        image_rgb = RGB_array(pixels)\n",
    "        \n",
    "#             edge_cal(file)\n",
    "        image_rgb=np.asarray(image_rgb)\n",
    "        print(np.shape(image_rgb))\n",
    "        image_rgb=image_rgb.reshape((10816,3))\n",
    "        train_x.append(image_rgb)\n",
    "        print(file,np.shape(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 2)\n",
      "(9, 10816, 3)\n"
     ]
    }
   ],
   "source": [
    "train_y = []\n",
    "train_y.append([1,0])\n",
    "train_y.append([1,0])\n",
    "train_y.append([0,1])\n",
    "train_y.append([0,1])\n",
    "train_y.append([0,1])\n",
    "train_y.append([1,0])\n",
    "train_y.append([1,0])\n",
    "train_y.append([0,1])\n",
    "train_y.append([1,0])\n",
    "train_y = np.array(train_y)\n",
    "print(np.shape(train_y))\n",
    "print(np.shape(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 10816, 3) (8, 2)\n"
     ]
    }
   ],
   "source": [
    "test_x = train_x[0]\n",
    "test_y = [1,0]\n",
    "train_x=np.delete(train_x,1,0)\n",
    "train_y=np.delete(train_y,1,0)\n",
    "print(np.shape(train_x),np.shape(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10816, 3)\n"
     ]
    }
   ],
   "source": [
    "test_x=test_x.reshape((1,10816, 3))\n",
    "print(np.shape(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2)\n"
     ]
    }
   ],
   "source": [
    "test_y= np.array(test_y)\n",
    "test_y=test_y.reshape((1,-1))\n",
    "print(np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init weight\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1) #normal distribution\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init bias\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "#     x input tensor of shape [batch, in_height, in_width, in_channels]\n",
    "# W filter/kernel tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "# strides[0]=strides[3]=1 strides[x] stands \"x\"direction, strides[y]stands \"y\" dicrection\n",
    "# padding: \"SAME\",OR \"VALID\"\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "#     ksize [1,x,y,1]\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 100\n",
    "\n",
    "# n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "batch_size=27\n",
    "\n",
    "#placeholder\n",
    "x = tf.placeholder(tf.float32,[None,10816,3])#104x104\n",
    "y = tf.placeholder(tf.float32,[None,2])\n",
    "\n",
    "# change X format into a 4D vector [batch, in_height, in_width, in_channels]\n",
    "x_image = tf.reshape(x,[-1,104,104,3])\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "# init first Convolutional Layer\n",
    "W_conv1 = weight_variable([5,5,3,32]) #5*5 window, 32 kernals extract feature from 3\n",
    "b_conv1 = bias_variable([32]) #each kernal 1 bias\n",
    "\n",
    "# Convolution using relu activation function\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) +b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)  #max-pooling\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "# init second Convolutional Layer\n",
    "W_conv2 = weight_variable([5,5,32,64]) #5*5 window, 64 kernals extract feature from 3\n",
    "b_conv2 = bias_variable([64]) #each kernal 1 bias\n",
    "\n",
    "# Convolution using relu activation function\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) +b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)  #max-pooling\n",
    "\n",
    "# 104*104 image → 52*52 after first pooling\n",
    "# 52*52 image → 26*26 after second pooling\n",
    "# get 64*26*26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init FC layer\n",
    "W_fc1 = weight_variable([64*26*26,1024]) #last layer 64*26*26 neurons\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# conver output of second pooling layer into 1 demonsion\n",
    "h_pool2_flat= tf.reshape(h_pool2, [-1,64*26*26])\n",
    "\n",
    "# first FC layer output\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "\n",
    "temp_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,temp_prob)\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "\n",
    "# second FC layer\n",
    "W_fc2 = weight_variable([1024,2])\n",
    "b_fc2 = bias_variable([2])\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "# output\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-4fa69210832d>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Iter 0,Testing Accuracy 1.0\n",
      "Iter 1,Testing Accuracy 1.0\n",
      "Iter 2,Testing Accuracy 1.0\n",
      "Iter 3,Testing Accuracy 1.0\n",
      "Iter 4,Testing Accuracy 1.0\n",
      "Iter 5,Testing Accuracy 1.0\n",
      "Iter 6,Testing Accuracy 1.0\n",
      "Iter 7,Testing Accuracy 1.0\n",
      "Iter 8,Testing Accuracy 1.0\n",
      "Iter 9,Testing Accuracy 1.0\n",
      "Iter 10,Testing Accuracy 1.0\n",
      "Iter 11,Testing Accuracy 1.0\n",
      "Iter 12,Testing Accuracy 1.0\n",
      "Iter 13,Testing Accuracy 1.0\n",
      "Iter 14,Testing Accuracy 1.0\n",
      "Iter 15,Testing Accuracy 1.0\n",
      "Iter 16,Testing Accuracy 1.0\n",
      "Iter 17,Testing Accuracy 1.0\n",
      "Iter 18,Testing Accuracy 1.0\n",
      "Iter 19,Testing Accuracy 1.0\n",
      "Iter 20,Testing Accuracy 1.0\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits = prediction))\n",
    "\n",
    "# AdamOptimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# store into a boolean list\n",
    "correct_prediction=  tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))#argmax return the position of the max number\n",
    "\n",
    "# get accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(21):\n",
    "        for batch in range(batch_size):\n",
    "            batch_xs,batch_ys =  train_x,train_y\n",
    "            \n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys, temp_prob:0.9 })\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:test_x,y:test_y, temp_prob:1.0 })\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
