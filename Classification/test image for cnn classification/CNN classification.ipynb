{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image, ImageStat\n",
    "import sys\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(dir):\n",
    "    file_list=listdir(dir)\n",
    "    for filename in file_list:\n",
    "        if \"panorama\" in filename and \"cropped\" not in filename:\n",
    "            path=\"\"\n",
    "            path=dir+filename\n",
    "            im=Image.open(path)\n",
    "            out=im.resize((104,208),Image.ANTIALIAS)\n",
    "            print (\"%s has been resized\"%filename)\n",
    "            out.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigS-0790_-37.80879980770527_144.98194564890238_panorama.png has been resized\n",
      "bigS-0820_-37.80878714139091_144.98228676055362_panorama.png has been resized\n",
      "bigS-0860_-37.80877025144173_144.98274157590654_panorama.png has been resized\n",
      "bigS-1060_-37.80868577546702_144.9850156495497_panorama.png has been resized\n",
      "bigS-2290_-37.80816528711204_144.99900108792806_panorama.png has been resized\n",
      "blackC-0850_-37.808774474092964_144.98262787208782_panorama.png has been resized\n",
      "blackC-0970_-37.80872379506533_144.98399231705417_panorama.png has been resized\n",
      "blackC-1010_-37.808706898558945_144.98444713162672_panorama.png has been resized\n",
      "blackC-1630_-37.80844477911086_144.99149673087072_panorama.png has been resized\n",
      "blackC-2520_-37.8080677765338_145.00161622930622_panorama.png has been resized\n",
      "buliding-0140_-37.80907400299053_144.9745548677395_panorama.png has been resized\n",
      "buliding-0380_-37.80897281542424_144.97728377794476_panorama.png has been resized\n",
      "buliding-1760_-37.808389765304874_144.99297486629814_panorama.png has been resized\n",
      "sky-1100_-37.80866887502632_144.98547046365388_panorama.png has been resized\n",
      "sky-1270_-37.80859702864577_144.98740342127365_panorama.png has been resized\n",
      "sky-1360_-37.808558979540216_144.98842675025523_panorama.png has been resized\n",
      "sky-1810_-37.80836860123093_144.99354337933758_panorama.png has been resized\n",
      "sky-2420_-37.80811017954074_145.00047921216438_panorama.png has been resized\n",
      "tree-0040_-37.80911614589736_144.9734178196137_panorama.png has been resized\n",
      "tree-0110_-37.809086647010126_144.97421375343805_panorama.png has been resized\n",
      "tree-0900_-37.80875335974397_144.9831963910514_panorama.png has been resized\n",
      "tree-0920_-37.80874491323935_144.9834237985458_panorama.png has been resized\n",
      "tree-2310_-37.808156810226265_144.99922849180032_panorama.png has been resized\n",
      "whiteB-0030_-37.80912035958696_144.97330411472973_panorama.png has been resized\n",
      "whiteB-0100_-37.80909086146474_144.9741000486449_panorama.png has been resized\n",
      "whiteB-0300_-37.80900655160748_144.9763741420407_panorama.png has been resized\n",
      "whiteB-0670_-37.80885046312688_144.98058120112736_panorama.png has been resized\n",
      "whiteB-1140_-37.80865197283703_144.98592527754985_panorama.png has been resized\n"
     ]
    }
   ],
   "source": [
    "path1 = r\"C:\\\\Users\\\\35252\\\\Desktop\\\\class\\\\\"\n",
    "files= listdir(path1)\n",
    "\n",
    "convert(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(image_path):\n",
    "    \"\"\"\n",
    "    Get a numpy 2D array of an image so that one can access RGBA[x][y] or RGBA[x,y].\n",
    "    \n",
    "    Also get a cropped image for further use for hsv and k-means clustering\n",
    "    \n",
    "    \"\"\"\n",
    "    origin = Image.open(image_path, 'r')\n",
    "    width, height = origin.size\n",
    "    area = (0, 0, width, 0.5*height)\n",
    "    image = origin.crop(area) # crop top half of the image\n",
    "#     result = Image.fromarray(image.astype(np.uint8))\n",
    "    image.save(file+\"_cropped.png\")\n",
    "    width, height = image.size\n",
    "#     print (image.size)\n",
    "    pixel_values = list(image.getdata())\n",
    "    if image.mode == 'RGBA':\n",
    "        channels = 4\n",
    "    elif image.mode == 'L':\n",
    "        channels = 1\n",
    "    else:\n",
    "        print(\"Unknown mode: %s\" % image.mode)\n",
    "        return None\n",
    "    pixel_values = np.array(pixel_values).reshape((height, width, channels))\n",
    "\n",
    "    return pixel_values #return pixels matrix with RGBA value, and cropped half image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_array(pixels):\n",
    "    \"\"\"\n",
    "    Get a numpy 2D array of an image so that one can access brightness[x][y]\n",
    "       \n",
    "    \"\"\"\n",
    "    rgb=[[0 for x in range(len(pixels[0]))] for y in range(len(pixels))]\n",
    "    # Matrix = [[0 for x in range(w)] for y in range(h)]\n",
    "    for i in range(len(pixels)):\n",
    "        for j in range(len(pixels[0])):\n",
    "            R,G,B,A=pixels[i,j]\n",
    "            rgb[i][j]=[R,G,B]\n",
    "    return rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 104, 3)\n",
      "bigS-0790_-37.80879980770527_144.98194564890238_panorama.png (1, 10816, 3)\n",
      "(104, 104, 3)\n",
      "bigS-0820_-37.80878714139091_144.98228676055362_panorama.png (2, 10816, 3)\n",
      "(104, 104, 3)\n",
      "bigS-0860_-37.80877025144173_144.98274157590654_panorama.png (3, 10816, 3)\n",
      "(104, 104, 3)\n",
      "bigS-1060_-37.80868577546702_144.9850156495497_panorama.png (4, 10816, 3)\n",
      "(104, 104, 3)\n",
      "bigS-2290_-37.80816528711204_144.99900108792806_panorama.png (5, 10816, 3)\n",
      "(104, 104, 3)\n",
      "blackC-0850_-37.808774474092964_144.98262787208782_panorama.png (6, 10816, 3)\n",
      "(104, 104, 3)\n",
      "blackC-0970_-37.80872379506533_144.98399231705417_panorama.png (7, 10816, 3)\n",
      "(104, 104, 3)\n",
      "blackC-1010_-37.808706898558945_144.98444713162672_panorama.png (8, 10816, 3)\n",
      "(104, 104, 3)\n",
      "blackC-1630_-37.80844477911086_144.99149673087072_panorama.png (9, 10816, 3)\n",
      "(104, 104, 3)\n",
      "blackC-2520_-37.8080677765338_145.00161622930622_panorama.png (10, 10816, 3)\n",
      "(104, 104, 3)\n",
      "buliding-0140_-37.80907400299053_144.9745548677395_panorama.png (11, 10816, 3)\n",
      "(104, 104, 3)\n",
      "buliding-0380_-37.80897281542424_144.97728377794476_panorama.png (12, 10816, 3)\n",
      "(104, 104, 3)\n",
      "buliding-1760_-37.808389765304874_144.99297486629814_panorama.png (13, 10816, 3)\n",
      "(104, 104, 3)\n",
      "sky-1100_-37.80866887502632_144.98547046365388_panorama.png (14, 10816, 3)\n",
      "(104, 104, 3)\n",
      "sky-1270_-37.80859702864577_144.98740342127365_panorama.png (15, 10816, 3)\n",
      "(104, 104, 3)\n",
      "sky-1360_-37.808558979540216_144.98842675025523_panorama.png (16, 10816, 3)\n",
      "(104, 104, 3)\n",
      "sky-1810_-37.80836860123093_144.99354337933758_panorama.png (17, 10816, 3)\n",
      "(104, 104, 3)\n",
      "sky-2420_-37.80811017954074_145.00047921216438_panorama.png (18, 10816, 3)\n",
      "(104, 104, 3)\n",
      "tree-0040_-37.80911614589736_144.9734178196137_panorama.png (19, 10816, 3)\n",
      "(104, 104, 3)\n",
      "tree-0110_-37.809086647010126_144.97421375343805_panorama.png (20, 10816, 3)\n",
      "(104, 104, 3)\n",
      "tree-0900_-37.80875335974397_144.9831963910514_panorama.png (21, 10816, 3)\n",
      "(104, 104, 3)\n",
      "tree-0920_-37.80874491323935_144.9834237985458_panorama.png (22, 10816, 3)\n",
      "(104, 104, 3)\n",
      "tree-2310_-37.808156810226265_144.99922849180032_panorama.png (23, 10816, 3)\n",
      "(104, 104, 3)\n",
      "whiteB-0030_-37.80912035958696_144.97330411472973_panorama.png (24, 10816, 3)\n",
      "(104, 104, 3)\n",
      "whiteB-0100_-37.80909086146474_144.9741000486449_panorama.png (25, 10816, 3)\n",
      "(104, 104, 3)\n",
      "whiteB-0300_-37.80900655160748_144.9763741420407_panorama.png (26, 10816, 3)\n",
      "(104, 104, 3)\n",
      "whiteB-0670_-37.80885046312688_144.98058120112736_panorama.png (27, 10816, 3)\n",
      "(104, 104, 3)\n",
      "whiteB-1140_-37.80865197283703_144.98592527754985_panorama.png (28, 10816, 3)\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "for file in sorted(files):\n",
    "    if \"panorama\" in file and \"cropped\" not in file:\n",
    "#         file=path1+file\n",
    "        pixels =get_image(file)\n",
    "#         print (np.shape(pixels))\n",
    "            # print (pixel1)\n",
    "        image_rgb = RGB_array(pixels)\n",
    "        \n",
    "#             edge_cal(file)\n",
    "        image_rgb=np.asarray(image_rgb)\n",
    "        print(np.shape(image_rgb))\n",
    "        image_rgb=image_rgb.reshape((10816,3))\n",
    "        train_x.append(image_rgb)\n",
    "        print(file,np.shape(train_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 6)\n"
     ]
    }
   ],
   "source": [
    "train_y = []\n",
    "for i in range(5):\n",
    "    train_y.append([1,0,0,0,0,0])\n",
    "for i in range(5):\n",
    "    train_y.append([0,1,0,0,0,0])\n",
    "for i in range(3):\n",
    "    train_y.append([0,0,1,0,0,0])\n",
    "for i in range(5):\n",
    "    train_y.append([0,0,0,1,0,0])\n",
    "for i in range(5):\n",
    "    train_y.append([0,0,0,0,1,0])\n",
    "for i in range(5):\n",
    "    train_y.append([0,0,0,0,0,1])\n",
    "train_y = np.array(train_y)\n",
    "print(np.shape(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27, 10816, 3) (27, 6)\n"
     ]
    }
   ],
   "source": [
    "test_x = train_x[0]\n",
    "test_y = train_y[0]\n",
    "train_x=np.delete(train_x,1,0)\n",
    "train_y=np.delete(train_y,1,0)\n",
    "print(np.shape(train_x),np.shape(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10816, 3)\n"
     ]
    }
   ],
   "source": [
    "test_x=test_x.reshape((1,10816, 3))\n",
    "print(np.shape(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6)\n"
     ]
    }
   ],
   "source": [
    "test_y= np.array(test_y)\n",
    "test_y=test_y.reshape((1,-1))\n",
    "print(np.shape(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init weight\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape,stddev = 0.1) #normal distribution\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init bias\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x,W):\n",
    "#     x input tensor of shape [batch, in_height, in_width, in_channels]\n",
    "# W filter/kernel tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "# strides[0]=strides[3]=1 strides[x] stands \"x\"direction, strides[y]stands \"y\" dicrection\n",
    "# padding: \"SAME\",OR \"VALID\"\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool_2x2(x):\n",
    "#     ksize [1,x,y,1]\n",
    "    return tf.nn.max_pool(x,ksize=[1,2,2,1],strides=[1,2,2,1],padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 100\n",
    "\n",
    "# n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "batch_size=27\n",
    "\n",
    "#placeholder\n",
    "x = tf.placeholder(tf.float32,[None,10816,3])#104x104\n",
    "y = tf.placeholder(tf.float32,[None,6])\n",
    "\n",
    "# change X format into a 4D vector [batch, in_height, in_width, in_channels]\n",
    "x_image = tf.reshape(x,[-1,104,104,3])\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "# init first Convolutional Layer\n",
    "W_conv1 = weight_variable([5,5,3,32]) #5*5 window, 32 kernals extract feature from 3\n",
    "b_conv1 = bias_variable([32]) #each kernal 1 bias\n",
    "\n",
    "# Convolution using relu activation function\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image,W_conv1) +b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)  #max-pooling\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "# init second Convolutional Layer\n",
    "W_conv2 = weight_variable([5,5,32,64]) #5*5 window, 64 kernals extract feature from 3\n",
    "b_conv2 = bias_variable([64]) #each kernal 1 bias\n",
    "\n",
    "# Convolution using relu activation function\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1,W_conv2) +b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)  #max-pooling\n",
    "\n",
    "# 104*104 image → 52*52 after first pooling\n",
    "# 52*52 image → 26*26 after second pooling\n",
    "# get 64*26*26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init FC layer\n",
    "W_fc1 = weight_variable([64*26*26,1024]) #last layer 64*26*26 neurons\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "# conver output of second pooling layer into 1 demonsion\n",
    "h_pool2_flat= tf.reshape(h_pool2, [-1,64*26*26])\n",
    "\n",
    "# first FC layer output\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat,W_fc1)+b_fc1)\n",
    "\n",
    "temp_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,temp_prob)\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "\n",
    "# second FC layer\n",
    "W_fc2 = weight_variable([1024,6])\n",
    "b_fc2 = bias_variable([6])\n",
    "\n",
    "\"\"\"\"\"\"\n",
    "# output\n",
    "prediction = tf.nn.softmax(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-ffdeae8478af>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ffdeae8478af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_ys\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_xs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_ys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m0.7\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_prob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EVAN_ALL\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EVAN_ALL\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EVAN_ALL\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EVAN_ALL\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EVAN_ALL\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\EVAN_ALL\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits = prediction))\n",
    "\n",
    "# AdamOptimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# store into a boolean list\n",
    "correct_prediction=  tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))#argmax return the position of the max number\n",
    "\n",
    "# get accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(21):\n",
    "        for batch in range(batch_size):\n",
    "            batch_xs,batch_ys =  train_x,train_y\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys, temp_prob:0.7 })\n",
    "        \n",
    "        acc = sess.run(accuracy,feed_dict={x:test_x,y:test_y, temp_prob:1.0 })\n",
    "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
